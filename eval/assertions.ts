/**
 * Eval-specific assertions for kata-wm agentic evals.
 *
 * All eval assertions live here. Scenarios import what they need —
 * individual assertions or preset arrays. No inline assertion
 * definitions in scenario files.
 */

import { readFileSync } from 'node:fs'
import { readNativeTaskFiles } from '../src/commands/enter/task-factory.js'
import type { EvalCheckpoint, EvalContext } from './harness.js'

// ─── Helpers ──────────────────────────────────────────────────────────────────

function pass(): string | null {
  return null
}

function fail(msg: string): string {
  return msg
}

/**
 * Read a top-level key from wm.yaml via grep.
 * Checks .kata/wm.yaml first (new layout), then .claude/workflows/wm.yaml (old layout).
 * Returns the value string or the provided default.
 */
function readWmYamlKey(ctx: EvalContext, key: string, fallback: string): string {
  // Try new layout first, then old layout
  const raw = ctx.run(
    `grep '^${key}:' .kata/wm.yaml 2>/dev/null || grep '^${key}:' .claude/workflows/wm.yaml 2>/dev/null`,
  )?.trim()
  if (!raw) return fallback
  // Extract value after "key: "
  const match = raw.match(new RegExp(`^${key}:\\s*(.+)$`))
  return match?.[1]?.trim() || fallback
}

// ─── Session State Assertions ──────────────────────────────────────────────────

/**
 * Assert that the session is in the given mode.
 */
export function assertCurrentMode(mode: string): EvalCheckpoint {
  return {
    name: `session.currentMode === '${mode}'`,
    assert(ctx: EvalContext) {
      const state = ctx.getSessionState()
      if (!state) return fail('Session state not found')
      if (state.currentMode !== mode) {
        return fail(`Expected currentMode '${mode}', got '${state.currentMode ?? 'undefined'}'`)
      }
      return pass()
    },
  }
}

/**
 * Assert that the session type matches.
 */
export function assertSessionType(sessionType: string): EvalCheckpoint {
  return {
    name: `session.sessionType === '${sessionType}'`,
    assert(ctx: EvalContext) {
      const state = ctx.getSessionState()
      if (!state) return fail('Session state not found')
      if (state.sessionType !== sessionType) {
        return fail(`Expected sessionType '${sessionType}', got '${state.sessionType ?? 'undefined'}'`)
      }
      return pass()
    },
  }
}

/**
 * Assert that the agent stayed in the given mode (no unexpected mode switches).
 */
export function assertStayedInMode(mode: string): EvalCheckpoint {
  return {
    name: `agent stayed in ${mode} mode`,
    assert(ctx: EvalContext) {
      const state = ctx.getSessionState()
      if (!state) return fail('Session state not found')
      const history: Array<{ mode: string }> = state.modeHistory ?? []
      const otherModes = history
        .map((h) => h.mode)
        .filter((m) => m !== mode && m !== 'default')
      if (otherModes.length > 0) {
        return fail(`Agent switched to other modes: ${otherModes.join(', ')}`)
      }
      return pass()
    },
  }
}

/**
 * Assert that a given mode appears in session history.
 */
export function assertModeInHistory(mode: string): EvalCheckpoint {
  return {
    name: `${mode} mode in session history`,
    assert(ctx: EvalContext) {
      const state = ctx.getSessionState()
      if (!state) return fail('Session state not found')
      const hasMode = state.modeHistory?.some((h) => h.mode === mode)
      if (!hasMode) {
        return fail(`${mode} mode not found in history: ${JSON.stringify(state.modeHistory)}`)
      }
      return pass()
    },
  }
}

// ─── Git Assertions ────────────────────────────────────────────────────────────

/**
 * Assert that at least one new commit was made beyond the initial fixture commit.
 */
export function assertNewCommit(): EvalCheckpoint {
  return {
    name: 'git: new commit created',
    assert(ctx: EvalContext) {
      const log = ctx.run('git log --oneline')
      const lines = log.split('\n').filter(Boolean)
      if (lines.length < 2) {
        return fail(`Expected at least 2 commits (fixture + new), found ${lines.length}`)
      }
      return pass()
    },
  }
}

/**
 * Assert that the working tree is clean (all changes committed).
 */
export function assertCleanWorkingTree(): EvalCheckpoint {
  return {
    name: 'git: working tree is clean',
    assert(ctx: EvalContext) {
      const status = ctx.run('git status --porcelain')
      const dirty = status.split('\n').filter((l) => l && !l.startsWith('??'))
      if (dirty.length > 0) {
        return fail(`Uncommitted tracked changes: ${dirty.slice(0, 3).join(', ')}`)
      }
      return pass()
    },
  }
}

/**
 * Assert that the diff vs initial commit contains a pattern.
 */
export function assertDiffContains(pattern: string | RegExp): EvalCheckpoint {
  const label = pattern instanceof RegExp ? pattern.source : pattern
  return {
    name: `git diff contains: ${label}`,
    assert(ctx: EvalContext) {
      // Diff against the initial fixture commit (root commit) so all agent
      // changes are visible regardless of how many commits were made.
      const initialSha = ctx.run('git rev-list --max-parents=0 HEAD')
      const diff = ctx.run(`git diff ${initialSha}..HEAD`)
      const matches = pattern instanceof RegExp ? pattern.test(diff) : diff.includes(pattern)
      if (!matches) {
        return fail(`Expected diff to contain '${label}'`)
      }
      return pass()
    },
  }
}

/**
 * Assert that the diff vs initial commit exceeds a minimum number of lines.
 * Used for implementation scenarios to verify substantive work.
 */
export function assertDiffNonTrivial(minLines: number): EvalCheckpoint {
  return {
    name: `git diff is non-trivial (>= ${minLines} lines)`,
    assert(ctx: EvalContext) {
      const initialSha = ctx.run('git rev-list --max-parents=0 HEAD')
      const diff = ctx.run(`git diff ${initialSha}..HEAD`)
      const lines = diff.split('\n').filter(Boolean).length
      if (lines < minLines) {
        return fail(`Expected diff >= ${minLines} lines, got ${lines}`)
      }
      return pass()
    },
  }
}

/**
 * Assert that all changes have been pushed to the remote.
 */
export function assertChangesPushed(): EvalCheckpoint {
  return {
    name: 'git: changes pushed to remote',
    assert(ctx: EvalContext) {
      const status = ctx.run('git status -sb')
      if (status.includes('ahead')) {
        return fail(`Unpushed commits: ${status.split('\n')[0]}`)
      }
      return pass()
    },
  }
}

// ─── File Assertions ───────────────────────────────────────────────────────────

/**
 * Assert that a file exists relative to the project dir.
 */
export function assertFileExists(relativePath: string): EvalCheckpoint {
  return {
    name: `file exists: ${relativePath}`,
    assert(ctx: EvalContext) {
      if (!ctx.fileExists(relativePath)) {
        return fail(`Expected file to exist: ${relativePath}`)
      }
      return pass()
    },
  }
}

/**
 * Assert that a file contains a string or matches a pattern.
 */
export function assertFileContains(relativePath: string, pattern: string | RegExp): EvalCheckpoint {
  const label = pattern instanceof RegExp ? pattern.source : pattern
  return {
    name: `${relativePath} contains: ${label}`,
    assert(ctx: EvalContext) {
      if (!ctx.fileExists(relativePath)) {
        return fail(`File not found: ${relativePath}`)
      }
      const content = ctx.readFile(relativePath)
      const matches = pattern instanceof RegExp ? pattern.test(content) : content.includes(pattern)
      if (!matches) {
        return fail(`Expected '${relativePath}' to contain '${label}'`)
      }
      return pass()
    },
  }
}

// ─── Artifact Assertions (config-driven) ─────────────────────────────────────

/**
 * Assert that at least one spec file (.md) exists in the configured spec_path.
 * Reads spec_path from wm.yaml, falls back to 'planning/specs'.
 */
export function assertSpecFileCreated(): EvalCheckpoint {
  return {
    name: 'spec file created',
    assert(ctx: EvalContext) {
      const specPath = readWmYamlKey(ctx, 'spec_path', 'planning/specs')
      const files = ctx.listDir(specPath)
      const specFiles = files.filter((f) => f.endsWith('.md'))
      if (specFiles.length === 0) {
        return fail(`No spec files found in ${specPath}/`)
      }
      return pass()
    },
  }
}

/**
 * Assert that at least one spec file has status: approved in its frontmatter.
 */
export function assertSpecApproved(): EvalCheckpoint {
  return {
    name: 'spec frontmatter: status: approved',
    assert(ctx: EvalContext) {
      const specPath = readWmYamlKey(ctx, 'spec_path', 'planning/specs')
      const files = ctx.listDir(specPath)
      const specFiles = files.filter((f) => f.endsWith('.md'))
      if (specFiles.length === 0) return fail('No spec files to check')

      for (const file of specFiles) {
        const content = ctx.readFile(`${specPath}/${file}`)
        if (content.includes('status: approved')) return pass()
      }
      return fail('No spec file with status: approved found')
    },
  }
}

/**
 * Assert that at least one spec file contains behavior sections (### B1:, ### B2:, etc.).
 */
export function assertSpecHasBehaviors(): EvalCheckpoint {
  return {
    name: 'spec contains behavior sections',
    assert(ctx: EvalContext) {
      const specPath = readWmYamlKey(ctx, 'spec_path', 'planning/specs')
      const files = ctx.listDir(specPath)
      const specFiles = files.filter((f) => f.endsWith('.md'))
      if (specFiles.length === 0) return fail('No spec files to check')

      for (const file of specFiles) {
        const content = ctx.readFile(`${specPath}/${file}`)
        if (/###\s+B\d+:/m.test(content)) return pass()
      }
      return fail('No behavior sections (### B1:) found in spec')
    },
  }
}

/**
 * Assert that at least one research doc (.md) exists in the configured research_path.
 * Reads research_path from wm.yaml, falls back to 'planning/research'.
 */
export function assertResearchDocCreated(): EvalCheckpoint {
  return {
    name: 'research document created',
    assert(ctx: EvalContext) {
      const researchPath = readWmYamlKey(ctx, 'research_path', 'planning/research')
      const docs = ctx.run(
        `find ${researchPath} -name "*.md" -type f 2>/dev/null | head -5`,
      )
      if (!docs || docs.trim().length === 0) {
        return fail(`No research doc found in ${researchPath}/`)
      }
      return pass()
    },
  }
}

/**
 * Assert that no .md files exist at a given path (e.g., no specs created during research).
 */
export function assertNoArtifacts(dirPath: string): EvalCheckpoint {
  return {
    name: `no artifacts in ${dirPath}`,
    assert(ctx: EvalContext) {
      const files = ctx.run(
        `find ${dirPath} -name "*.md" -type f 2>/dev/null | head -5`,
      )
      if (files && files.trim().length > 0) {
        return fail(`Unexpected artifacts in ${dirPath}: ${files.trim()}`)
      }
      return pass()
    },
  }
}

// ─── Onboard Assertions ──────────────────────────────────────────────────────

/**
 * Assert that .claude/settings.json exists and has hooks configured.
 */
export function assertSettingsExist(): EvalCheckpoint {
  return {
    name: '.claude/settings.json exists with hooks',
    assert(ctx: EvalContext) {
      if (!ctx.fileExists('.claude/settings.json')) {
        return fail('.claude/settings.json not found')
      }
      const content = ctx.readFile('.claude/settings.json')
      try {
        const settings = JSON.parse(content)
        if (!settings.hooks) {
          return fail('settings.json has no hooks key')
        }
        if (!settings.hooks.SessionStart) {
          return fail('settings.json missing SessionStart hook')
        }
        return pass()
      } catch {
        return fail('settings.json is not valid JSON')
      }
    },
  }
}

/**
 * Assert that wm.yaml exists with a project: key.
 * Checks .kata/wm.yaml (new layout) then .claude/workflows/wm.yaml (old layout).
 */
export function assertWmYamlExists(): EvalCheckpoint {
  return {
    name: 'wm.yaml exists',
    assert(ctx: EvalContext) {
      const newPath = '.kata/wm.yaml'
      const oldPath = '.claude/workflows/wm.yaml'
      const wmPath = ctx.fileExists(newPath) ? newPath : ctx.fileExists(oldPath) ? oldPath : null
      if (!wmPath) {
        return fail('wm.yaml not found (checked .kata/wm.yaml and .claude/workflows/wm.yaml)')
      }
      const content = ctx.readFile(wmPath)
      if (!content.includes('project:')) {
        return fail('wm.yaml missing project: key')
      }
      return pass()
    },
  }
}

/**
 * Assert that mode templates have been seeded.
 * Checks .kata/templates/ (new layout) then .claude/workflows/templates/ (old layout).
 */
export function assertTemplatesExist(): EvalCheckpoint {
  return {
    name: 'mode templates seeded',
    assert(ctx: EvalContext) {
      const newDir = '.kata/templates'
      const oldDir = '.claude/workflows/templates'
      const templates = ctx.listDir(newDir)
      if (templates.length > 0) {
        if (!templates.includes('onboard.md')) {
          return fail('onboard.md template missing from .kata/templates/')
        }
        return pass()
      }
      const oldTemplates = ctx.listDir(oldDir)
      if (oldTemplates.length === 0) {
        return fail('No templates found (checked .kata/templates/ and .claude/workflows/templates/)')
      }
      if (!oldTemplates.includes('onboard.md')) {
        return fail('onboard.md template missing from .claude/workflows/templates/')
      }
      return pass()
    },
  }
}

/**
 * Assert that the project is a git repository.
 */
export function assertGitInitialized(): EvalCheckpoint {
  return {
    name: 'git repository initialized',
    assert(ctx: EvalContext) {
      const result = ctx.run('git rev-parse --git-dir 2>/dev/null')
      if (!result) {
        return fail('Not a git repository')
      }
      return pass()
    },
  }
}

// ─── Delta Assertions (for live projects with baselineRef) ────────────────────

/**
 * Assert that at least one new commit was made since the baseline ref.
 * For live project scenarios where there's no "initial scaffold" commit.
 */
export function assertNewCommitSinceBaseline(): EvalCheckpoint {
  return {
    name: 'git: new commit since baseline',
    assert(ctx: EvalContext) {
      if (!ctx.baselineRef) {
        return fail('No baselineRef set — this assertion requires a live project scenario')
      }
      const count = ctx.run(`git rev-list --count ${ctx.baselineRef}..HEAD`)
      if (!count || parseInt(count, 10) < 1) {
        return fail(`Expected at least 1 new commit since ${ctx.baselineRef.slice(0, 8)}, found 0`)
      }
      return pass()
    },
  }
}

/**
 * Assert that the diff since baseline contains a pattern.
 * Like assertDiffContains but uses baselineRef instead of root commit.
 */
export function assertDeltaDiffContains(pattern: string | RegExp): EvalCheckpoint {
  const label = pattern instanceof RegExp ? pattern.source : pattern
  return {
    name: `delta diff contains: ${label}`,
    assert(ctx: EvalContext) {
      if (!ctx.baselineRef) {
        return fail('No baselineRef set — this assertion requires a live project scenario')
      }
      const diff = ctx.run(`git diff ${ctx.baselineRef}..HEAD`)
      const matches = pattern instanceof RegExp ? pattern.test(diff) : diff.includes(pattern)
      if (!matches) {
        return fail(`Expected delta diff (since ${ctx.baselineRef.slice(0, 8)}) to contain '${label}'`)
      }
      return pass()
    },
  }
}

/**
 * Assert that a session state file exists with a mode set.
 * Works with both .kata/ and .claude/ layouts.
 */
export function assertSessionInitialized(): EvalCheckpoint {
  return {
    name: 'session state initialized with mode',
    assert(ctx: EvalContext) {
      const state = ctx.getSessionState()
      if (!state) {
        return fail('No session state found')
      }
      if (!state.currentMode) {
        return fail('Session state exists but currentMode is not set')
      }
      return pass()
    },
  }
}

// ─── kata can-exit Assertion ───────────────────────────────────────────────────

/**
 * Assert that kata can-exit returns 0 (all tasks complete, conditions met).
 */
export function assertCanExit(): EvalCheckpoint {
  return {
    name: 'kata can-exit: exits 0',
    assert(ctx: EvalContext) {
      const output = ctx.run('kata can-exit 2>&1; echo "EXIT:$?"')
      if (!output.includes('EXIT:0')) {
        return fail(`kata can-exit did not exit 0. Output: ${output.slice(0, 200)}`)
      }
      return pass()
    },
  }
}

// ─── Task Discipline Assertions ──────────────────────────────────────────────

/**
 * Assert that all pre-created native tasks have status: 'completed'.
 * Requires sessionId on the EvalContext.
 */
export function assertAllNativeTasksCompleted(): EvalCheckpoint {
  return {
    name: 'all native tasks completed',
    assert(ctx: EvalContext) {
      if (!ctx.sessionId) {
        return fail('No sessionId on EvalContext — cannot check native tasks')
      }
      const tasks = readNativeTaskFiles(ctx.sessionId)
      if (tasks.length === 0) {
        return fail('No native task files found')
      }
      const pending = tasks.filter((t) => t.status !== 'completed')
      if (pending.length > 0) {
        const summary = pending.map((t) => `[${t.id}] ${t.subject} (${t.status})`).join('; ')
        return fail(`${pending.length} native task(s) not completed: ${summary}`)
      }
      return pass()
    },
  }
}

/**
 * Assert that the transcript contains no TaskCreate tool_use blocks.
 * Agents should use pre-created native tasks, not create their own.
 * Requires transcriptPath on the EvalContext.
 */
export function assertNoTaskCreateCalls(): EvalCheckpoint {
  return {
    name: 'no TaskCreate calls in transcript',
    assert(ctx: EvalContext) {
      if (!ctx.transcriptPath) {
        return fail('No transcriptPath on EvalContext — cannot check transcript')
      }
      let content: string
      try {
        content = readFileSync(ctx.transcriptPath, 'utf-8')
      } catch {
        return fail(`Cannot read transcript: ${ctx.transcriptPath}`)
      }
      // Each line is a JSON event; look for tool_use blocks with name TaskCreate
      const lines = content.split('\n').filter(Boolean)
      for (const line of lines) {
        try {
          const event = JSON.parse(line)
          if (event.type === 'assistant' && event.message?.content) {
            for (const block of event.message.content) {
              if (block.type === 'tool_use' && block.name === 'TaskCreate') {
                return fail('Agent called TaskCreate — should use pre-created native tasks instead')
              }
            }
          }
        } catch {
          // Skip unparseable lines
        }
      }
      return pass()
    },
  }
}

/**
 * Assert that at least N native tasks exist for the session.
 * Sanity check that tasks were actually created by kata enter.
 */
export function assertNativeTaskCount(min: number): EvalCheckpoint {
  return {
    name: `native task count >= ${min}`,
    assert(ctx: EvalContext) {
      if (!ctx.sessionId) {
        return fail('No sessionId on EvalContext — cannot check native tasks')
      }
      const tasks = readNativeTaskFiles(ctx.sessionId)
      if (tasks.length < min) {
        return fail(`Expected >= ${min} native tasks, found ${tasks.length}`)
      }
      return pass()
    },
  }
}

/**
 * Assert that no completed task has an incomplete blocker.
 * Verifies the agent respected the dependency chain.
 */
export function assertTaskDependencyOrderRespected(): EvalCheckpoint {
  return {
    name: 'task dependency order respected',
    assert(ctx: EvalContext) {
      if (!ctx.sessionId) {
        return fail('No sessionId on EvalContext — cannot check native tasks')
      }
      const tasks = readNativeTaskFiles(ctx.sessionId)
      if (tasks.length === 0) {
        return fail('No native task files found')
      }
      const statusById = new Map(tasks.map((t) => [t.id, t.status]))
      for (const task of tasks) {
        if (task.status === 'completed') {
          for (const blockerId of task.blockedBy) {
            const blockerStatus = statusById.get(blockerId)
            if (blockerStatus && blockerStatus !== 'completed') {
              return fail(
                `Task [${task.id}] completed but blocker [${blockerId}] is '${blockerStatus}'`,
              )
            }
          }
        }
      }
      return pass()
    },
  }
}

// ─── Task Generation Assertions ──────────────────────────────────────────────

/**
 * Assert that at least one native task has metadata.originalId matching the given suffix.
 * Verifies that subphase pattern expansion created the expected task IDs.
 * Example: assertNativeTaskHasOriginalId('p2.1:impl') checks for impl task of first spec phase.
 */
export function assertNativeTaskHasOriginalId(suffix: string): EvalCheckpoint {
  return {
    name: `native task exists with originalId: ${suffix}`,
    assert(ctx: EvalContext) {
      if (!ctx.sessionId) {
        return fail('No sessionId on EvalContext — cannot check native tasks')
      }
      const tasks = readNativeTaskFiles(ctx.sessionId)
      if (tasks.length === 0) {
        return fail('No native task files found')
      }
      const match = tasks.find(
        (t) => (t.metadata as Record<string, unknown>)?.originalId === suffix,
      )
      if (!match) {
        const ids = tasks
          .map((t) => (t.metadata as Record<string, unknown>)?.originalId)
          .filter(Boolean)
          .join(', ')
        return fail(
          `No native task with originalId '${suffix}'. Found: ${ids}`,
        )
      }
      return pass()
    },
  }
}

/**
 * Assert that at least one native task's description matches the given pattern.
 * Verifies that instruction/agent metadata from subphase patterns carried through
 * to the native task description field.
 */
export function assertNativeTaskHasInstruction(pattern: string | RegExp): EvalCheckpoint {
  const label = pattern instanceof RegExp ? pattern.source : pattern
  return {
    name: `native task has instruction: ${label}`,
    assert(ctx: EvalContext) {
      if (!ctx.sessionId) {
        return fail('No sessionId on EvalContext — cannot check native tasks')
      }
      const tasks = readNativeTaskFiles(ctx.sessionId)
      if (tasks.length === 0) {
        return fail('No native task files found')
      }
      const matches = pattern instanceof RegExp
        ? tasks.some((t) => pattern.test(t.description))
        : tasks.some((t) => t.description.includes(pattern))
      if (!matches) {
        return fail(
          `No native task description matches '${label}'. ` +
          `Descriptions: ${tasks.map((t) => t.description.slice(0, 60)).join(' | ')}`,
        )
      }
      return pass()
    },
  }
}

/**
 * Implementation task generation presets for a 2-phase spec with impl-test pattern.
 * Verifies the 2-step subphase pattern expanded correctly into native tasks.
 * P3 Verify phase (kata verify-run) is a separate orchestration task, not per-subphase.
 */
export function implTaskGenPresets(): EvalCheckpoint[] {
  return [
    assertNativeTaskHasOriginalId('p2.1:impl'),
    assertNativeTaskHasOriginalId('p2.1:test'),
    assertNativeTaskHasOriginalId('p2.2:impl'),
    assertNativeTaskHasOriginalId('p2.2:test'),
    assertNativeTaskHasInstruction(/check-phase/),
  ]
}

// ─── Stop Hook Assertions ────────────────────────────────────────────────────

interface StopHookLogEntry {
  ts: string
  decision: 'block' | 'allow'
  reasons: string[]
  note?: string
}

/**
 * Read stop hook log entries for a session.
 * The stop hook writes to {sessionsDir}/{sessionId}/stop-hook.log.jsonl
 */
function readStopHookLog(ctx: EvalContext): StopHookLogEntry[] {
  // Check both session dir layouts
  for (const base of ['.kata/sessions', '.claude/sessions']) {
    if (!ctx.sessionId) return []
    const logPath = `${base}/${ctx.sessionId}/stop-hook.log.jsonl`
    if (ctx.fileExists(logPath)) {
      const content = ctx.readFile(logPath)
      return content
        .split('\n')
        .filter(Boolean)
        .map((line) => {
          try {
            return JSON.parse(line) as StopHookLogEntry
          } catch {
            return null
          }
        })
        .filter((e): e is StopHookLogEntry => e !== null)
    }
  }
  return []
}

/**
 * Assert that the stop hook blocked the agent at least N times.
 * Requires sessionId on EvalContext and stop-hook.log.jsonl in the session dir.
 */
export function assertStopHookBlocked(minTimes: number = 1): EvalCheckpoint {
  return {
    name: `stop hook blocked >= ${minTimes} time(s)`,
    assert(ctx: EvalContext) {
      if (!ctx.sessionId) {
        return fail('No sessionId on EvalContext — cannot check stop hook log')
      }
      const entries = readStopHookLog(ctx)
      if (entries.length === 0) {
        return fail('No stop hook log entries found — hook may not have fired')
      }
      const blocks = entries.filter((e) => e.decision === 'block')
      if (blocks.length < minTimes) {
        return fail(
          `Expected stop hook to block >= ${minTimes} time(s), got ${blocks.length}. ` +
          `Total hook firings: ${entries.length}`,
        )
      }
      return pass()
    },
  }
}

/**
 * Assert that the stop hook blocked with a reason matching the given pattern.
 * Useful for verifying specific conditions were enforced (e.g., 'pending', 'Uncommitted').
 */
export function assertStopHookBlockedWithReason(pattern: string | RegExp): EvalCheckpoint {
  const label = pattern instanceof RegExp ? pattern.source : pattern
  return {
    name: `stop hook blocked with reason: ${label}`,
    assert(ctx: EvalContext) {
      if (!ctx.sessionId) {
        return fail('No sessionId on EvalContext — cannot check stop hook log')
      }
      const entries = readStopHookLog(ctx)
      const blocks = entries.filter((e) => e.decision === 'block')
      if (blocks.length === 0) {
        return fail('Stop hook never blocked — cannot check reasons')
      }
      const allReasons = blocks.flatMap((e) => e.reasons)
      const matches = pattern instanceof RegExp
        ? allReasons.some((r) => pattern.test(r))
        : allReasons.some((r) => r.includes(pattern))
      if (!matches) {
        return fail(
          `No stop hook block had reason matching '${label}'. ` +
          `Reasons seen: ${allReasons.slice(0, 5).join('; ')}`,
        )
      }
      return pass()
    },
  }
}

/**
 * Assert that the stop hook eventually allowed exit (last entry is 'allow').
 */
export function assertStopHookEventuallyAllowed(): EvalCheckpoint {
  return {
    name: 'stop hook eventually allowed exit',
    assert(ctx: EvalContext) {
      if (!ctx.sessionId) {
        return fail('No sessionId on EvalContext — cannot check stop hook log')
      }
      const entries = readStopHookLog(ctx)
      if (entries.length === 0) {
        return fail('No stop hook log entries found')
      }
      const last = entries[entries.length - 1]
      if (last.decision !== 'allow') {
        return fail(
          `Last stop hook decision was '${last.decision}', expected 'allow'. ` +
          `Reasons: ${last.reasons.join('; ')}`,
        )
      }
      return pass()
    },
  }
}

// ─── Hook Log Assertions ────────────────────────────────────────────────────

interface HookLogEntry {
  ts: string
  hook: string
  decision: string
  [key: string]: unknown
}

/**
 * Read the unified hook log for a session.
 * Hooks write to {sessionsDir}/{sessionId}/hooks.log.jsonl
 */
function readHookLog(ctx: EvalContext): HookLogEntry[] {
  for (const base of ['.kata/sessions', '.claude/sessions']) {
    if (!ctx.sessionId) return []
    const logPath = `${base}/${ctx.sessionId}/hooks.log.jsonl`
    if (ctx.fileExists(logPath)) {
      const content = ctx.readFile(logPath)
      return content
        .split('\n')
        .filter(Boolean)
        .map((line) => {
          try {
            return JSON.parse(line) as HookLogEntry
          } catch {
            return null
          }
        })
        .filter((e): e is HookLogEntry => e !== null)
    }
  }
  return []
}

/**
 * Assert that a specific hook fired at least once.
 * Checks hooks.log.jsonl for entries matching the hook name.
 */
export function assertHookFired(hookName: string): EvalCheckpoint {
  return {
    name: `hook fired: ${hookName}`,
    assert(ctx: EvalContext) {
      const entries = readHookLog(ctx)
      if (entries.length === 0) {
        return fail('No hook log entries found — hooks.log.jsonl missing or empty')
      }
      const matches = entries.filter((e) => e.hook === hookName)
      if (matches.length === 0) {
        const seen = [...new Set(entries.map((e) => e.hook))].join(', ')
        return fail(`Hook '${hookName}' never fired. Hooks seen: ${seen}`)
      }
      return pass()
    },
  }
}

/**
 * Assert that a specific hook made a specific decision at least once.
 */
export function assertHookDecision(hookName: string, decision: string): EvalCheckpoint {
  return {
    name: `hook ${hookName}: decision=${decision}`,
    assert(ctx: EvalContext) {
      const entries = readHookLog(ctx)
      const matches = entries.filter((e) => e.hook === hookName && e.decision === decision)
      if (matches.length === 0) {
        const hookEntries = entries.filter((e) => e.hook === hookName)
        if (hookEntries.length === 0) {
          return fail(`Hook '${hookName}' never fired`)
        }
        const decisions = hookEntries.map((e) => e.decision).join(', ')
        return fail(`Hook '${hookName}' never decided '${decision}'. Decisions seen: ${decisions}`)
      }
      return pass()
    },
  }
}

/**
 * Assert that the mode-gate hook denied at least one tool call.
 * Checks hooks.log.jsonl for mode-gate entries with decision=deny.
 */
export function assertModeGateBlocked(): EvalCheckpoint {
  return {
    name: 'mode-gate: blocked at least one edit without mode',
    assert(ctx: EvalContext) {
      const entries = readHookLog(ctx)
      const denials = entries.filter((e) => e.hook === 'mode-gate' && e.decision === 'deny')
      if (denials.length > 0) return pass()

      // Fallback: check transcript for the denial message (pre-logging compat)
      if (ctx.transcriptPath) {
        try {
          const content = readFileSync(ctx.transcriptPath, 'utf-8')
          if (
            content.includes('Enter a mode first') ||
            content.includes('Write operations are blocked until a mode is active')
          ) {
            return pass()
          }
        } catch {
          // ignore
        }
      }

      return fail(
        'No mode-gate denial found. Agent may have entered a mode before attempting edits.',
      )
    },
  }
}

/**
 * Assert that the transcript contains a string pattern.
 * Useful for verifying hook outputs, system messages, or tool results.
 */
export function assertTranscriptContains(pattern: string, label?: string): EvalCheckpoint {
  return {
    name: label ?? `transcript contains: ${pattern.slice(0, 60)}`,
    assert(ctx: EvalContext) {
      if (!ctx.transcriptPath) {
        return fail('No transcriptPath — cannot check transcript')
      }
      let content: string
      try {
        content = readFileSync(ctx.transcriptPath, 'utf-8')
      } catch {
        return fail(`Cannot read transcript: ${ctx.transcriptPath}`)
      }
      if (!content.includes(pattern)) {
        return fail(`Pattern not found in transcript: "${pattern.slice(0, 80)}"`)
      }
      return pass()
    },
  }
}

// ─── Interview Assertions ─────────────────────────────────────────────────────

/**
 * Known interview category headers from batteries/interviews.yaml.
 * Used to verify that captured questions look like real interview rounds.
 */
const INTERVIEW_HEADERS = new Set([
  // P0: scope clarification
  'Feature', 'Issue', 'Approve',
  // P1: interview categories from batteries/interviews.yaml
  'Problem', 'Happy Path', 'Scope OUT', 'Empty State', 'Scale', 'Concurrency',
  'Integration', 'Errors', 'Performance',
  'Error Paths', 'Test Types',
  'Reference', 'Layout', 'Components',
])

/**
 * Assert that .eval/pending-question.json contains an interview-like AskUserQuestion.
 * Checks:
 * - File exists and is valid JSON
 * - Has a sessionId
 * - Has at least 1 question with header, question text, and 2+ options
 * - At least one header matches a known interview category
 */
export function assertInterviewQuestionCaptured(): EvalCheckpoint {
  return {
    name: 'interview AskUserQuestion captured',
    assert(ctx: EvalContext) {
      if (!ctx.fileExists('.eval/pending-question.json')) {
        return fail('No .eval/pending-question.json — AskUserQuestion was not intercepted')
      }

      let data: Record<string, unknown>
      try {
        data = JSON.parse(ctx.readFile('.eval/pending-question.json'))
      } catch {
        return fail('.eval/pending-question.json is not valid JSON')
      }

      if (!data.sessionId) {
        return fail('pending-question.json has no sessionId')
      }

      const questions = data.questions as Array<Record<string, unknown>> | undefined
      if (!questions || questions.length === 0) {
        return fail('pending-question.json has no questions')
      }

      // Validate structure: each question needs header, question, options (2+)
      for (let i = 0; i < questions.length; i++) {
        const q = questions[i]
        if (!q.header || !q.question) {
          return fail(`Question ${i} missing header or question text`)
        }
        const opts = q.options as Array<unknown> | undefined
        if (!opts || opts.length < 2) {
          return fail(`Question ${i} has < 2 options (got ${opts?.length ?? 0})`)
        }
      }

      // At least one header should match a known interview category
      const headers = questions.map((q) => String(q.header))
      const matched = headers.some((h) => INTERVIEW_HEADERS.has(h))
      if (!matched) {
        return fail(
          `No question header matches interview categories. Headers seen: ${headers.join(', ')}`,
        )
      }

      return pass()
    },
  }
}

// ─── Presets ──────────────────────────────────────────────────────────────────

/**
 * Standard workflow presets: correct mode, committed, clean tree, can-exit.
 */
export function workflowPresets(mode: string): EvalCheckpoint[] {
  return [
    assertCurrentMode(mode),
    assertNewCommit(),
    assertCleanWorkingTree(),
    assertCanExit(),
  ]
}

/**
 * Workflow presets that also require changes pushed to remote.
 */
export function workflowPresetsWithPush(mode: string): EvalCheckpoint[] {
  return [
    ...workflowPresets(mode),
    assertChangesPushed(),
  ]
}

/**
 * Planning mode presets: workflow + spec created/approved/has behaviors.
 */
export function planningPresets(mode: string = 'planning'): EvalCheckpoint[] {
  return [
    ...workflowPresetsWithPush(mode),
    assertSpecFileCreated(),
    assertSpecApproved(),
    assertSpecHasBehaviors(),
    assertModeInHistory(mode),
  ]
}

/**
 * Live project workflow presets: session initialized, mode correct,
 * new commit since baseline, clean tree, can-exit.
 * For scenarios running against real projects (not fixtures).
 */
export function liveWorkflowPresets(mode: string): EvalCheckpoint[] {
  return [
    assertSessionInitialized(),
    assertCurrentMode(mode),
    assertNewCommitSinceBaseline(),
    assertCleanWorkingTree(),
    assertCanExit(),
  ]
}

/**
 * Stop hook enforcement presets: hook fired, blocked at least once,
 * blocked for pending tasks, and eventually allowed exit.
 */
export function stopHookPresets(): EvalCheckpoint[] {
  return [
    assertStopHookBlocked(1),
    assertStopHookBlockedWithReason(/task.*pending/i),
    assertStopHookEventuallyAllowed(),
  ]
}

/**
 * Task discipline presets: native tasks created, no TaskCreate calls,
 * all tasks completed, dependency order respected.
 */
export function taskDisciplinePresets(): EvalCheckpoint[] {
  return [
    assertNativeTaskCount(3),
    assertNoTaskCreateCalls(),
    assertAllNativeTasksCompleted(),
    assertTaskDependencyOrderRespected(),
  ]
}

/**
 * Live project + task discipline: session init, mode, commit, clean tree,
 * can-exit, plus full task discipline checks.
 */
export function liveTaskDisciplinePresets(mode: string): EvalCheckpoint[] {
  return [
    ...liveWorkflowPresets(mode),
    ...taskDisciplinePresets(),
  ]
}

/**
 * Onboard presets: git init, settings, wm.yaml, templates.
 */
export const onboardPresets: EvalCheckpoint[] = [
  assertGitInitialized(),
  assertSettingsExist(),
  assertWmYamlExists(),
  assertTemplatesExist(),
]
